{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual pathway architecture\n",
    "\n",
    "Author: Remya Sankar\n",
    "\n",
    "This notebook simulates sensorimotor learning using a dual pathway architecture, as explained in the article\n",
    "\"Dual pathway architecture underlying sensorimotor learning in birds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np                                         # 1.16.2 \n",
    "import matplotlib.pyplot as plt                            # 3.0.3\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.ndimage import filters\n",
    "from scipy.interpolate import interp2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, rseed=3456, run=0, n_distractors=20, noiseLim=0.2, fig_path='Figures/', eta=0.1, n_days=60, ntrialspday=1000, simulation=True, contour_type='Syrinx', reward_contour_path='Contours/rc4/Z-T03_P005_n10.npy', syrinx_param_range = [0, 0.2, 0, 1], img_format='png', dpi=300, plt_close='True'):\n",
    "        \"\"\" Initialisation. \"\"\"\n",
    "        \n",
    "        self.rseed = rseed\n",
    "        self.run = run\n",
    "        self.n_distractors = n_distractors\n",
    "        self.noiseLim = noiseLim\n",
    "        self.fig_path = fig_path\n",
    "        self.eta = eta\n",
    "        self.n_days = n_days                                     # No. of days for learning\n",
    "        self.ntrialspday = ntrialspday                           # No. of trials per day\n",
    "        self.img_format = img_format\n",
    "        self.fig_name = self.fig_path + str(self.run) + '_' + str(self.rseed) + '_' + str(self.n_distractors) + '_'\n",
    "        self.contour_type = contour_type                         # \"Syrinx\" / \"Artificial\"\n",
    "        self.reward_contour_path = reward_contour_path\n",
    "        self.syrinx_param_range = syrinx_param_range\n",
    "        if simulation == False: self.load_simulation()\n",
    "        self.rasterized = True\n",
    "        self.dpi = dpi\n",
    "        self.plt_close = plt_close\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def hill(self, sigma=0.1, center=None):\n",
    "        \"\"\" Randomly assigns the mean and std deviation for the hills in the reward contour. \"\"\"\n",
    "\n",
    "        if center is None:\n",
    "            r = np.sqrt(np.random.uniform(0.0, 1.0))\n",
    "            a = np.random.uniform(0, 2*np.pi)\n",
    "            center = r*np.cos(a), r*np.sin(a)\n",
    "\n",
    "        return center, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def gaussian(self, n=128, center=(0,0), sigma=0.1):\n",
    "        \"\"\" Creates a 2D gaussian distribution, given the center coordinates and std deviation. \"\"\"\n",
    "\n",
    "        X, Y = np.meshgrid(np.linspace(-1, +1, n), np.linspace(-1, +1, n))\n",
    "        x0, y0 = center\n",
    "        D = np.sqrt((X-x0)**2/(2*sigma**2) + (Y-y0)**2/(2*sigma**2))\n",
    "\n",
    "        return 1/(2*np.pi*sigma**2)*np.exp(-D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def generate_gradient(self, n=256):\n",
    "        \"\"\" Redirects to the function that generates the desired contour type \"\"\"\n",
    "        \n",
    "        if self.contour_type == 'Syrinx': return self.generate_gradient_syrinx(n)\n",
    "        elif self.contour_type == 'Artificial': return self.generate_gradient_artificial(n)\n",
    "        else: print(\"Contour type not specified (Syrinx/Artificial).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def generate_gradient_syrinx(self, n=256):\n",
    "        \"\"\" Loads the reward contour from the syrinx model. Outer product and applies a filter.\"\"\"\n",
    "        \n",
    "        # Load generated reward contour\n",
    "        Z = np.load(self.reward_contour_path)\n",
    "        Z = Z / Z.max()\n",
    "        \n",
    "        # Transform exponentially\n",
    "        Z = np.power(1000, Z)\n",
    "        Z = Z / Z.max()\n",
    "\n",
    "        # Interpolate\n",
    "        x = np.linspace(0, 1., Z.shape[0])\n",
    "        y = np.linspace(0, .2, Z.shape[1])\n",
    "        \n",
    "        x2 = np.linspace(0, 1., n)\n",
    "        y2 = np.linspace(0, .2, n)\n",
    "        f = interp2d(x, y, Z, kind='cubic')\n",
    "        Z = f(x2, y2)\n",
    "        \n",
    "        Z = (Z-np.min(Z))/(np.max(Z)-np.min(Z))\n",
    "        Z = Z / Z.max()\n",
    "    \n",
    "        targetZpos = np.argwhere(Z==1)[0]\n",
    "        self.targetpos = np.zeros((2))\n",
    "        self.targetpos[0] = (targetZpos[1] / Z.shape[1]) * 2 - 1\n",
    "        self.targetpos[1] = (targetZpos[0] / Z.shape[0]) * 2 - 1\n",
    "                \n",
    "        return  Z / Z.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def generate_gradient_artificial(self, n=256):\n",
    "        \"\"\" Creates the overall reward contour by combining several gaussians. \"\"\"\n",
    "        \n",
    "        # No. of local optima\n",
    "        n_hills = self.n_distractors\n",
    "\n",
    "        # Target i.e. global optima\n",
    "        target_r = np.random.uniform(0,1)\n",
    "        target_theta = np.random.uniform(0,2*np.pi)\n",
    "        self.targetpos = target_r*np.cos(target_theta), target_r*np.sin(target_theta)\n",
    "        hills = [self.hill(0.3, self.targetpos)] # chosen sigma=0.3\n",
    "\n",
    "        # n_hills distractors (0.4 < Ïƒ < 0.7) i.e. local optima\n",
    "        for i in range(n_hills):\n",
    "            hills.append(self.hill(np.random.uniform(0.4, 0.7)))\n",
    "\n",
    "        # Build gradient landscape\n",
    "        Z = np.zeros((n,n))\n",
    "        for (center, sigma) in hills:\n",
    "            Z = np.maximum(Z, self.gaussian(n, center, sigma))\n",
    "            # Z = Z + gaussian(n, center, sigma)    # For a smoother reward profile    \n",
    "        \n",
    "        return  Z / Z.max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def read_gradient(self, Z, p):\n",
    "        \"\"\" Returns height of reward profile at given position. \"\"\"\n",
    "\n",
    "        x = min(max(p[0], -1), 1)\n",
    "        y = min(max(p[1], -1), 1)\n",
    "        col = int(((x + 1)/2) * (Z.shape[1]-1))\n",
    "        row = int(((y + 1)/2) * (Z.shape[0]-1))\n",
    "\n",
    "        return Z[row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def running_mean(self, x, N=5):\n",
    "        \"\"\" Returns the running average of an array. \"\"\"\n",
    "\n",
    "        rm = np.convolve(x, np.ones(N)/N, mode='valid')\n",
    "        padded_rm = np.ones(np.shape(x)) * rm[-1]\n",
    "        padded_rm[:rm.size] = rm\n",
    "\n",
    "        return padded_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def var_windows(self, x, n=50):\n",
    "        \"\"\" Returns the windowed variance of an array. \"\"\"\n",
    "\n",
    "        if x.shape[1] == 2: distances = np.sqrt(np.sum(x**2, axis=-1))\n",
    "        else: distances = x\n",
    "        a = np.reshape(distances, (int(self.ntrials/n), n))\n",
    "        win_var = np.var(a, axis=1)\n",
    "\n",
    "        return win_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def length(self, Z):\n",
    "        \"\"\" Returns the length of a vector. \"\"\"\n",
    "\n",
    "        return np.sqrt((Z*Z).sum())\n",
    "\n",
    "class Model(Model):\n",
    "    def clip(self, Z, lim=1):\n",
    "        \"\"\" Bounds the vector to the range of a circle of radius=lim. \"\"\"\n",
    "        \n",
    "        return np.clip(Z, -lim, lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def find_peaks(self, Z, n=256):\n",
    "        \"\"\" Finds the peaks in a given contour. \"\"\"\n",
    "\n",
    "        peaks = []\n",
    "        for x in np.arange(n):\n",
    "            for y in np.arange(n):\n",
    "                curr = Z[x,y]\n",
    "                left_x = np.maximum(0,x-1)\n",
    "                right_x = np.minimum(n-1,x+1)\n",
    "                bottom_y = np.maximum(0,y-1)\n",
    "                top_y = np.minimum(n-1,y+1)\n",
    "\n",
    "                if curr > Z[left_x,y] and curr > Z[x,bottom_y] and curr > Z[x,top_y] and curr > Z[right_x,y]:\n",
    "                    peaks.append([x/(n-1) * 2 - 1, y/(n-1) * 2 - 1])\n",
    "\n",
    "        return np.array(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def simulate(self):\n",
    "        \"\"\" Runs the simulation and returns the performance metrics. \"\"\"\n",
    "\n",
    "        # Overall simulation parameters\n",
    "        np.random.seed(self.rseed)\n",
    "\n",
    "        # --- Simulated annealing --- #\n",
    "\n",
    "        self.Z = self.generate_gradient()  # Creates reward profile\n",
    "\n",
    "        # Parameters\n",
    "        stepsize = self.noiseLim                             # Radius of local exploration\n",
    "        eta = self.eta                                            # Learning rate of BG pathway\n",
    "        HL_eta = self.eta/100                                      # Learning rate of cortical pathway\n",
    "        self.ntrials = self.n_days * self.ntrialspday        # Total no. of trials\n",
    "\n",
    "        # For tracking purposes\n",
    "        self.Noise = np.zeros((self.ntrials,2))              # Tracks noise across trials\n",
    "        self.R = np.zeros((self.ntrials,1))                    # Tracks reward obtained across trials\n",
    "        self.P = np.zeros((self.ntrials,2))                  # Tracks overall trajectory\n",
    "        self.P_rl = np.zeros((self.ntrials,2))               # Tracks mean of BG exploration \n",
    "        self.P_hl = np.zeros((self.ntrials,2))               # Tracks location of cortical pathway\n",
    "        self.W_hl = np.zeros((self.ntrials,1))               # Tracks influence of cortical pathway across trials\n",
    "        self.W_rl = np.zeros((self.ntrials,1))               # Tracks influence of BG pathway across trials\n",
    "        self.BG = np.zeros((self.ntrials,2))                 # Tracks weighted output of BG pathway\n",
    "        self.CTX = np.zeros((self.ntrials,2))                # Tracks weighted output of cortical pathway\n",
    "        self.Rdiff = np.zeros((self.ntrials,1))                # Tracks weighted output of cortical pathway\n",
    "        self.Rinteg = np.zeros((self.ntrials,1))                # Tracks weighted output of cortical pathway\n",
    "\n",
    "\n",
    "        # Changing influence of cortical and BG pathway\n",
    "        q = np.linspace(0, 10, self.ntrials+1)[1:]            \n",
    "        self.W_hl = np.exp(-.5/q)\n",
    "        self.W_rl = 1-np.exp(-1/q)\n",
    "        \n",
    "\n",
    "        # Initialisations for first trial\n",
    "        p_hl = np.zeros((2,))\n",
    "        p_rl = np.random.uniform(-1, 1, p_hl.shape)\n",
    "        w_hl = 0\n",
    "        w_rl = 1\n",
    "        BG_cntr = w_rl * p_rl\n",
    "        ctx_cntr = w_hl * p_hl\n",
    "        p = ctx_cntr + BG_cntr\n",
    "\n",
    "        current_r = self.read_gradient(self.Z, p)\n",
    "\n",
    "        # Track\n",
    "        self.R[0] = current_r\n",
    "        self.P[0] = p\n",
    "        self.P_rl[0] = p_rl \n",
    "        self.P_hl[0] = p_hl\n",
    "        self.W_rl[0] = 1\n",
    "        self.BG[0] = BG_cntr\n",
    "        self.CTX[0] = ctx_cntr\n",
    "\n",
    "        # Simulate each day\n",
    "        for day,k in enumerate(np.linspace(0, 10, self.n_days)):\n",
    "            \n",
    "            # Simulate each trial in a day\n",
    "            for i,t in enumerate(np.linspace(0, 10, self.ntrialspday)):        \n",
    "\n",
    "                j = day * self.ntrialspday + i \n",
    "                if j==0:\n",
    "                    i+=1                                         # j=0 is already calculated during initialisations\n",
    "                    j+=1\n",
    "\n",
    "                w_rl = self.W_rl[j]\n",
    "                w_hl = self.W_hl[j]\n",
    "\n",
    "                # Local exploration\n",
    "                noise = np.random.uniform(-1,1, p_hl.shape) * stepsize\n",
    "                BG_cntr = w_rl * self.clip(p_rl + noise)\n",
    "                ctx_cntr = self.clip(w_hl * p_hl)\n",
    "                p = self.clip(ctx_cntr + BG_cntr)\n",
    "\n",
    "                # Performance evaluation\n",
    "                r = self.read_gradient(self.Z, p)\n",
    "                prev_r = np.mean( self.R[ np.maximum(0,j-100) : j ] )\n",
    "                rdiff = r - prev_r \n",
    "                binary_RPE = (rdiff > 0)\n",
    "#                 cont_RPE = np.maximum(0, rdiff)\n",
    "                RPE = binary_RPE\n",
    "\n",
    "                # RL update\n",
    "                p_rl = self.clip(p_rl + eta * noise * RPE)\n",
    "        \n",
    "                # HL update\n",
    "                p_hl = self.clip(p_hl + HL_eta * BG_cntr)\n",
    "\n",
    "                # Record trajectory\n",
    "                self.P[j] = p\n",
    "                self.P_rl[j] = p_rl\n",
    "                self.P_hl[j] = p_hl\n",
    "                self.Noise[j] = noise\n",
    "                self.BG[j] = BG_cntr\n",
    "                self.CTX[j] = ctx_cntr\n",
    "                self.R[j] = r\n",
    "                self.Rdiff[j] = rdiff\n",
    "\n",
    "            # New RL position for new day\n",
    "            jump = np.random.uniform(-1, 1, p_hl.shape)\n",
    "            daily_contRPE = np.maximum(0,self.Rdiff)\n",
    "            daily_LTP = np.mean(daily_contRPE[day*self.ntrialspday : (day+1)*self.ntrialspday])\n",
    "            \n",
    "            Rweightage = daily_LTP * 8\n",
    "            if Rweightage > .8: print(str(self.rseed) + 'exceeds Rweightage limits: ' + str(Rweightage))\n",
    "            Rweightage = self.clip(Rweightage, .8)\n",
    "            \n",
    "            p_rl = self.clip(Rweightage * p_rl + (1-Rweightage) * jump) # Weighted displacement\n",
    "            self.Rinteg[j] = Rweightage\n",
    "    \n",
    "            \n",
    "#         self.plot_results()\n",
    "        \n",
    "        self.distance_optima = self.distance_performance()\n",
    "        self.reward_performance = np.mean(self.R[-5 * self.ntrialspday:])   \n",
    "        self.n_local_optima = self.find_peaks(self.Z).shape[0]\n",
    "        self.performance_metric = [self.reward_performance, self.distance_optima, self.n_local_optima]\n",
    "        \n",
    "#         np.save(self.fig_name + 'object_variables', vars(self)) # Use better method\n",
    "        \n",
    "        return self.performance_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plotting ---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def load_simulation(self):\n",
    "        \"\"\" Loads previously saved simulation. \"\"\"\n",
    "        \n",
    "        stored_state=(np.load(self.fig_name + 'object_variables.npy')).item()\n",
    "        self.__dict__ = stored_state\n",
    "        \n",
    "        np.save(self.fig_name + 'object_variables', vars(self))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def distance_performance(self):\n",
    "        \"\"\" Computes the performance metric based on distance from global optima. \"\"\"\n",
    "        \n",
    "        if self.contour_type == 'Syrinx':\n",
    "        \n",
    "            optima1 = np.array([85,85]) / self.Z.shape * 2 - 1\n",
    "            optima2 = np.array([194,56]) / self.Z.shape * 2 - 1\n",
    "            optima3 = np.array([0,113]) / self.Z.shape * 2 - 1\n",
    "\n",
    "            position_last5days = self.P[-5 * self.ntrialspday:]\n",
    "\n",
    "            distance_optima1 = np.mean(np.sqrt(np.sum((position_last5days - optima1)**2, axis=1)))\n",
    "            distance_optima2 = np.mean(np.sqrt(np.sum((position_last5days - optima2)**2, axis=1)))\n",
    "            distance_optima3 = np.mean(np.sqrt(np.sum((position_last5days - optima3)**2, axis=1)))\n",
    "\n",
    "            return [distance_optima1, distance_optima2, distance_optima3]\n",
    "        \n",
    "        elif self.contour_type == 'Artificial':\n",
    "            \n",
    "            optima1 = self.targetpos\n",
    "            position_last5days = self.P[-5 * self.ntrialspday:]\n",
    "            distance_optima1 = np.mean(np.sqrt(np.sum((position_last5days - optima1)**2, axis=1)))\n",
    "            \n",
    "            return [distance_optima1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_results(self):\n",
    "        \"\"\" Specifies the different plots to be generated. \"\"\"\n",
    "        \n",
    "        self.plot_trajectory()\n",
    "        self.plot_exploration()\n",
    "        self.plot_coordinates()\n",
    "        self.plot_rewarddiff_integ()\n",
    "#         self.plot_reward()\n",
    "#         self.plot_HLdiff()\n",
    "#         self.plot_variance()\n",
    "#         self.plot_CI()        \n",
    "#         self.plot_reward_variance()\n",
    "        \n",
    "#         np.save(self.fig_name + 'object_variables', vars(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_gradient(self, ax, Z):\n",
    "        \"\"\" Plots reward contour. \"\"\"\n",
    "\n",
    "        contour = ax.contourf(Z, 30, extent=[-1,1,-1,1], cmap=\"gray_r\", alpha=.25)\n",
    "\n",
    "        contour = ax.contour(Z, 10, extent=[-1,1,-1,1],\n",
    "                             colors=\"black\",  alpha=.5, linewidths=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_landscape(self):\n",
    "        \"\"\" Plots the contours of the performance landscape. \"\"\"\n",
    "\n",
    "        figure = plt.figure(figsize=(8,8))\n",
    "        ax = plt.subplot(frameon=True)\n",
    "\n",
    "        # Plot reward contour as circles around hills    \n",
    "        self.plot_gradient(ax, self.Z)\n",
    "\n",
    "        # Plot reward contour as a color plot\n",
    "        im = ax.imshow(self.Z , vmin=0, vmax=np.max(self.Z), cmap='Purples', extent=[-1,1,-1,1], origin='lower')\n",
    "#         ax.invert_yaxis()                                                          # Labels read top-to-bottom\n",
    "\n",
    "\n",
    "#         ax.spines['top'].set_visible(False)\n",
    "#         ax.spines['right'].set_visible(False)\n",
    "        if self.contour_type=='Syrinx':\n",
    "            ax.set_xlabel(r'$P_{\\beta} (Tension)$', fontsize=20)\n",
    "            ax.set_ylabel(r'$P_{\\alpha} (Pressure)$', fontsize=20)\n",
    "        else:\n",
    "            ax.set_xlabel(r'$P_{\\beta}$', fontsize=40)\n",
    "            ax.set_ylabel(r'$P_{\\alpha}$', fontsize=40)\n",
    "        ax.set_xticks(np.linspace(-1, 1, 3))\n",
    "        ax.set_yticks(np.linspace(-1, 1, 3))\n",
    "        ax.tick_params(labelsize=35)\n",
    "        \n",
    "        if self.contour_type=='Syrinx':\n",
    "            ax.set_xticklabels(np.linspace(self.syrinx_param_range[2], self.syrinx_param_range[3], 3), fontsize=15)\n",
    "            ax.set_yticklabels(np.linspace(self.syrinx_param_range[0], self.syrinx_param_range[1], 3), fontsize=15)\n",
    "\n",
    "\n",
    "\n",
    "        # ax.legend(loc='upper left', bbox_to_anchor=[-0.1,1])\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(self.fig_name + 'trajectory.' + self.img_format, format=self.img_format, bbox_inches=\"tight\", rasterized=self.rasterized)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_trajectory(self):\n",
    "        \"\"\" Plots the trajectory of the model output and the cortical motor pathway over the simulation. \"\"\"\n",
    "\n",
    "        figure = plt.figure(figsize=(8,8))\n",
    "        ax = plt.subplot(frameon=True)\n",
    "        \n",
    "        sk=4\n",
    "\n",
    "        # Plot reward contour as circles around hills    \n",
    "        self.plot_gradient(ax, self.Z)\n",
    "\n",
    "        # Plot reward contour as a color plot\n",
    "        im = ax.imshow(self.Z , vmin=0, vmax=np.max(self.Z), cmap='Purples', extent=[-1,1,-1,1], origin='lower')\n",
    "#         ax.invert_yaxis()                                                          # Labels read top-to-bottom\n",
    "\n",
    "        # Plot trajectory\n",
    "        ax.plot(self.P[::sk,0::sk],self.P[::sk,1::sk], color=\"black\", lw=0, marker='.', alpha=0.5, markersize=2)\n",
    "#         ax.plot(self.CTX[:,0],self.CTX[:,1], color=\"white\", lw=0, marker='.', alpha=0.5, markersize=3)\n",
    "        ax.plot(self.CTX[::sk,0::sk],self.CTX[::sk,1::sk], color=\"sienna\", lw=0, marker='.', alpha=0.5, markersize=4)\n",
    "\n",
    "        # Annotations\n",
    "        ax.scatter(self.CTX[0,0],self.CTX[0,1], color=\"sienna\", marker=\"o\",\n",
    "                   linewidths=3, facecolors=\"sienna\", zorder=10, label='Initial point')\n",
    "        ax.scatter(self.P[-1,0],self.P[-1,1], s=100, color=\"orange\", marker=\"x\",\n",
    "                   linewidths=3, facecolors=\"orange\", zorder=10, label='Final point')\n",
    "\n",
    "        \n",
    "        # Display colorbar\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.5)\n",
    "        cbar = figure.colorbar(im, cax=cax, ticks=[0, .5, 1])\n",
    "        cbar.set_label('Performance metric (R)', rotation=270, fontsize=25, labelpad=25)\n",
    "        cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "#         ax.spines['top'].set_visible(False)\n",
    "#         ax.spines['right'].set_visible(False)\n",
    "        if self.contour_type=='Syrinx':\n",
    "            ax.set_xlabel(r'$P_{\\beta} (Tension)$', fontsize=20)\n",
    "            ax.set_ylabel(r'$P_{\\alpha} (Pressure)$', fontsize=20)\n",
    "        else:\n",
    "            ax.set_xlabel(r'$P_{\\beta}$', fontsize=30)\n",
    "            ax.set_ylabel(r'$P_{\\alpha}$', fontsize=30)\n",
    "        ax.set_xticks(np.linspace(-1, 1, 3))\n",
    "        ax.set_yticks(np.linspace(-1, 1, 3))\n",
    "        ax.tick_params(labelsize=25)\n",
    "        \n",
    "        if self.contour_type=='Syrinx':\n",
    "            ax.set_xticklabels(np.linspace(self.syrinx_param_range[2], self.syrinx_param_range[3], 3), fontsize=15)\n",
    "            ax.set_yticklabels(np.linspace(self.syrinx_param_range[0], self.syrinx_param_range[1], 3), fontsize=15)\n",
    "\n",
    "\n",
    "\n",
    "        # ax.legend(loc='upper left', bbox_to_anchor=[-0.1,1])\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(self.fig_name + 'trajectory.' + self.img_format, format=self.img_format, bbox_inches=\"tight\", rasterized=self.rasterized, dpi=self.dpi)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_exploration(self):\n",
    "        \"\"\" Plots the contribution of the exploratory pathway over the simulation. \"\"\"\n",
    "\n",
    "        figure = plt.figure(figsize=(8,8))\n",
    "        ax = plt.subplot(aspect=1)\n",
    "        \n",
    "        sk=4\n",
    "\n",
    "        # Plot exploration across time\n",
    "        exp_cm = plt.set_cmap('plasma')\n",
    "        exp_x = self.BG[:,0]\n",
    "        exp_y = self.BG[:,1]\n",
    "        exp_z = np.arange(exp_x.size)\n",
    "        exp_sc = plt.scatter(exp_x[::sk], exp_y[::sk], c=exp_z[::sk], s=4, cmap=exp_cm, marker='.', vmin=0, vmax=exp_x.size, alpha=0.5)\n",
    "\n",
    "        # Annotations\n",
    "        ax.scatter(0, 0, color=\"black\", marker=\"o\",\n",
    "                   linewidths=3, facecolors=\"black\", zorder=10, label='$P_{ctx}$')\n",
    "\n",
    "        ax.annotate('$P_{mtr}$', (0, 0),\n",
    "                    xytext=(-0.3, 0.3), xycoords='data',\n",
    "                    arrowprops=dict(width=1, facecolor='black', shrink=0.1),\n",
    "                    fontsize=30,\n",
    "                    horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "        # Display colorbar\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.5)\n",
    "        cbar = figure.colorbar(exp_sc, cax=cax)\n",
    "        cbar.set_ticks(np.linspace(0, exp_x.size, self.n_days/20+1))\n",
    "        cbar.set_ticklabels(np.arange(0, self.n_days+1, 20))\n",
    "        cbar.set_label('Day', rotation=270, fontsize=20, labelpad=20)\n",
    "        cbar.ax.tick_params(labelsize=15)\n",
    "\n",
    "        ax.set_xlim(-1,1)\n",
    "        ax.set_ylim(-1,1)\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(True)\n",
    "        ax.spines['left'].set_visible(True)\n",
    "        \n",
    "        # Plot scale at bottom left\n",
    "        ax.spines['left'].set_bounds(-1, -.9)\n",
    "        ax.spines['bottom'].set_bounds(-1, -.9)\n",
    "        ax.text(-1.05,-.95,'0.1',rotation=90,ha='center',va='center',fontsize=15)\n",
    "        ax.text(-.95,-1.05,'0.1',ha='center',va='center',fontsize=15)\n",
    "\n",
    "        ax.get_xaxis().set_ticks([])\n",
    "        ax.get_yaxis().set_ticks([])\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(self.fig_name + 'exploration.' + self.img_format, format=self.img_format, bbox_inches='tight', rasterized=self.rasterized, dpi=self.dpi)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_coordinates(self):\n",
    "        \"\"\" Plots the model output over time. \"\"\"\n",
    "\n",
    "        figure, (ax1, ax2) = plt.subplots(2,1)\n",
    "        \n",
    "        sk = 20\n",
    "\n",
    "        # Display x axis in days\n",
    "        x = np.arange(self.ntrials)\n",
    "        x = x/self.ntrialspday\n",
    "\n",
    "        # Plot running average of cortical output (brown), BG output (grey) and total output (black)\n",
    "        ax1.plot(x[::sk], self.running_mean(self.P[:,0])[::sk], color=\"black\", lw=1, label='Total output')\n",
    "        ax1.plot(x[::sk], self.running_mean(self.CTX[:,0])[::sk], color=\"sienna\", lw=2, label='Cortical output')\n",
    "        ax1.plot(x[::sk], self.running_mean(self.BG[:,0])[::sk], color=\"grey\", lw=1, label='BG output', alpha=0.5)\n",
    "        ax1.axhline(y=0, linestyle='--', color='black', alpha=0.1)\n",
    "        ax1.axhline(y=self.targetpos[0], linestyle='--', color='black', label='Global optimum')\n",
    "\n",
    "        ax2.axhline(y=self.targetpos[1], linestyle='--', color='black', label='Global optimum')\n",
    "        ax2.plot(x[::sk], self.running_mean(self.P[:,1])[::sk], color=\"black\", lw=1, label='$P$')\n",
    "        ax2.plot(x[::sk], self.running_mean(self.BG[:,1])[::sk], color=\"grey\", lw=1, label='$P_{rl}$', alpha=0.5)\n",
    "        ax2.plot(x[::sk], self.running_mean(self.CTX[:,1])[::sk], color=\"sienna\", lw=2, label='$P_{mtr}$')\n",
    "        ax2.axhline(y=0, linestyle='--', color='black', alpha=0.1)\n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.spines['bottom'].set_visible(False)\n",
    "        ax1.spines['bottom'].set_bounds(0, self.n_days)\n",
    "        ax1.get_xaxis().set_ticks([])\n",
    "        ax1.set_xlim(-1, self.n_days)\n",
    "        ax1.set_ylim(-1, 1)\n",
    "        ax1.tick_params(labelsize=15)\n",
    "        \n",
    "        \n",
    "        if self.contour_type=='Syrinx':\n",
    "            ax1.set_ylabel(r'$P_{\\beta} (Tension)$', fontsize=20)\n",
    "            ax2.set_ylabel(r'$P_{\\alpha} (Pressure)$', fontsize=20)\n",
    "        else:\n",
    "            ax1.set_ylabel(r'$P_{\\beta}$', fontsize=20)\n",
    "            ax2.set_ylabel(r'$P_{\\alpha}$', fontsize=20)\n",
    "        \n",
    "        plt.legend(frameon=False, loc='center right', fontsize=12, bbox_to_anchor=(1.03,1))\n",
    "\n",
    "\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.spines['bottom'].set_bounds(0, self.n_days)\n",
    "        ax1.spines['bottom'].set_bounds(0, self.n_days)\n",
    "        ax2.set_xlabel('Days', fontsize=20)\n",
    "        ax2.set_xlim(-1, self.n_days)\n",
    "        ax2.set_ylim(-1, 1)\n",
    "        ax2.get_xaxis().set_ticks([0, 20, 40, 60])\n",
    "        ax2.tick_params(labelsize=15)\n",
    "\n",
    "        ax1.set_yticks([-1, 0, 1])\n",
    "        ax2.set_yticks([-1, 0, 1])\n",
    "        if self.contour_type=='Syrinx':\n",
    "            ax1.set_yticklabels(np.linspace(self.syrinx_param_range[2], self.syrinx_param_range[3], 3))\n",
    "            ax2.set_yticklabels(np.linspace(self.syrinx_param_range[0], self.syrinx_param_range[1], 3))\n",
    "\n",
    "\n",
    "            \n",
    "        # Save figure\n",
    "        plt.savefig(self.fig_name + 'coordinates.' + self.img_format, format=self.img_format, bbox_inches='tight', rasterized=self.rasterized, dpi=self.dpi)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_reward(self):\n",
    "        \"\"\" Plots the reward obtained over time. \"\"\"\n",
    "\n",
    "        figure, ax = plt.subplots(1)\n",
    "        \n",
    "        # Display x axis in days\n",
    "        x = np.linspace(0, self.n_days, self.ntrials)\n",
    "\n",
    "        ax.plot(x, self.R, color=\"purple\", lw=0, alpha=0.7, label='Reward', marker=',')\n",
    "        ax.plot(x, self.Noise[:,0] * self.W_rl, color=\"grey\", lw=0.5, alpha=0.4, label='Noise weighted')\n",
    "        ax.plot(x, self.Noise[:,0], color=\"grey\", lw=0.5, alpha=0.2, label='Noise')\n",
    "\n",
    "        ax.set_ylim(-0.45, 1.1)\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('Days')\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        plt.savefig(self.fig_name + 'reward.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_influence(self):\n",
    "        \"\"\" Plots the change in influence of the two pathways over time. \"\"\"\n",
    "\n",
    "        figure, ax = plt.subplots(1)\n",
    "\n",
    "        ax.plot(self.W_hl, color=\"sienna\", lw=1, label='Cortical influence')\n",
    "        ax.plot(self.W_rl, color=\"grey\", lw=1, label='BG influence')\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        ax.set_xlabel('Trials')\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_HLdiff(self):\n",
    "        \"\"\" Plots the change in the cortical output per trial and per day. \"\"\"\n",
    "\n",
    "        figure, ax1 = plt.subplots(1)\n",
    "\n",
    "        hldiff = np.sqrt(np.sum((self.CTX[1:] - self.CTX[:-1])**2, axis=-1))\n",
    "        \n",
    "        # Display x axis in days\n",
    "        x = np.linspace(0, self.n_days, self.ntrials)\n",
    "\n",
    "        ax1.plot(x[:-1], hldiff, color=\"black\", marker=',', lw=0, alpha=0.2)\n",
    "        ax1.set_ylabel('Trial by trial difference')\n",
    "        ax1.set_xlabel('Days')\n",
    "        \n",
    "        ax2 = ax1.twinx() \n",
    "        \n",
    "        P2 = self.CTX.reshape((self.n_days, self.ntrialspday, 2))\n",
    "        CTX_start = P2[:,0]\n",
    "        CTX_end = P2[:,-1]\n",
    "        hldiff_day = np.sqrt(np.sum((CTX_end - CTX_start)**2, axis=-1))\n",
    "\n",
    "        x = np.arange(0, self.n_days)\n",
    "        ax2.plot(x, hldiff_day, color=\"sienna\", marker='.', lw=0)\n",
    "        \n",
    "        ax2.set_ylabel('Day wise difference', color=\"sienna\")\n",
    "        ax2.tick_params(axis ='y', labelcolor = \"sienna\", color=\"sienna\") \n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "\n",
    "        plt.savefig(self.fig_name + 'HL_diff.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_variance(self):\n",
    "        \"\"\" Plots the variance over time. \"\"\"\n",
    "\n",
    "        figure, ax1 = plt.subplots(1)\n",
    "        \n",
    "        window_size = 50\n",
    "        \n",
    "        # Display x axis in days\n",
    "        x = np.linspace(0, self.n_days, self.ntrials/window_size)\n",
    "\n",
    "        ax1.plot(x, self.var_windows(self.P, window_size), color=\"black\", marker='.', lw=0, alpha=0.5, label='Total')\n",
    "        ax1.plot(x, self.var_windows(self.BG, window_size), color=\"grey\", marker='x', lw=0, alpha=0.5, label='BG')\n",
    "        ax1.set_ylabel('Variance')\n",
    "        ax1.set_xlabel('Days')\n",
    "    \n",
    "        ax2 = ax1.twinx() \n",
    "        ax2.plot(x, self.var_windows(self.CTX, window_size), color=\"sienna\", marker='.', lw=0, alpha=0.5, label='CTX')\n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.tick_params(axis ='y', labelcolor = \"sienna\", color=\"sienna\")\n",
    "        \n",
    "        ax1.legend()\n",
    "        ax2.set_ylabel('Cortex variance', color=\"sienna\")\n",
    "\n",
    "        plt.savefig(self.fig_name + 'variance.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_CI(self):\n",
    "        \"\"\" Plots the consolidation index over time. \"\"\"\n",
    "\n",
    "        variance = self.var_windows(self.P)\n",
    "        variance = variance.reshape((self.n_days, int(variance.size/self.n_days)))\n",
    "        variance_start = variance[:,0]\n",
    "        variance_end = variance[:,-1]\n",
    "        span = variance_end - variance_start\n",
    "        shift = variance_start[1:] - variance_end[:-1]\n",
    "        CI = shift/span[:-1]\n",
    "        CI = CI[(CI < 5) & (CI > -5)]\n",
    "        \n",
    "        figure, ax1 = plt.subplots(1)\n",
    "        \n",
    "        n, bins, patches = plt.hist(CI, 40, density=True, facecolor='black', alpha=0.75)\n",
    "        \n",
    "        ax1.set_xlabel('Consolidation index (shift/span)')\n",
    "        ax1.set_ylabel('Density')\n",
    "    \n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        \n",
    "        plt.savefig(self.fig_name + 'CI.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_reward_variance(self):\n",
    "        \"\"\" Plots the variance in reward obtained over time. \"\"\"\n",
    "\n",
    "        figure, ax1 = plt.subplots(1)\n",
    "\n",
    "        window_size = 50\n",
    "\n",
    "        # Display x axis in days\n",
    "        x = np.linspace(0, self.n_days, self.ntrials/window_size)\n",
    "        \n",
    "        ax1.plot(x, self.var_windows(self.R, window_size), color=\"purple\", marker='.', lw=0, alpha=0.5, label='Total')\n",
    "        ax1.set_ylabel('Variance')\n",
    "        ax1.set_xlabel('Days')\n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        \n",
    "        ax1.legend()\n",
    "\n",
    "        plt.savefig(self.fig_name + 'reward_variance.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_rewarddiff_integ(self):\n",
    "        \"\"\" Plots the variance in reward obtained over time. \"\"\"\n",
    "\n",
    "        figure, ax1 = plt.subplots(1)\n",
    "        \n",
    "        sk = 10\n",
    "\n",
    "        # Display x axis in days\n",
    "        x = np.linspace(0, self.n_days, self.ntrials/sk)\n",
    "                \n",
    "#         ax1.plot(x, self.Rdiff, linewidth=0, marker=',', color='grey', alpha=0.2, label='RPE value per trial (RPE_val)')\n",
    "        ax1.plot(x, self.R[::sk], linewidth=0, marker='.', color='purple', alpha=0.4, markersize=2)\n",
    "        ax1.plot(x, self.running_mean(self.R[:,0], 100)[::sk], color=\"purple\", lw=0.5, markersize=4)#, label='$\\overline{R_{100}}$')\n",
    "\n",
    "        ax1.plot(np.arange(1,self.n_days+1), self.Rinteg[self.ntrialspday-1:self.ntrials:self.ntrialspday], linewidth=0, marker='.', color='black', label='Daily LTP strength')\n",
    "        \n",
    "        ax1.set_ylabel('Performance evaluation (R)', fontsize=20)\n",
    "        ax1.set_xlabel('Days', fontsize=20)\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.spines['bottom'].set_bounds(0, self.n_days)\n",
    "        ax1.set_ylim(0,1)\n",
    "        ax1.get_yaxis().set_ticks([0,.5,1])\n",
    "        ax1.get_xaxis().set_ticks(np.linspace(0, self.n_days, self.n_days/20+1))\n",
    "        ax1.tick_params(labelsize=15)\n",
    "        \n",
    "#         ax1.legend(frameon=False, loc='upper left', fontsize=12, bbox_to_anchor=[-.14, -.07], handletextpad=0)\n",
    "        \n",
    "        axins = ax1.inset_axes([.6, 0.2, .4, 0.4])\n",
    "        \n",
    "        x_zoom = np.linspace(20, 30, self.ntrialspday*10)\n",
    "        axins.plot(x_zoom, self.R[self.ntrialspday*20:self.ntrialspday*30], linewidth=0, marker=',', color='purple', alpha=0.2)\n",
    "        axins.plot(x_zoom, self.running_mean(self.R[self.ntrialspday*20:self.ntrialspday*30,0], 100), color=\"purple\", lw=0.5, label='R_{100}/')\n",
    "\n",
    "        axins.set_xlim(20, 30)\n",
    "        axins.set_ylim(.5, 1)\n",
    "        axins.get_xaxis().set_ticks([])\n",
    "        axins.get_yaxis().set_ticks([])\n",
    "        ax1.indicate_inset_zoom(axins)\n",
    "        \n",
    "#         lgd = ax1.legend(frameon=False)\n",
    "#         lgd.get_texts()[0].set_color('grey')\n",
    "#         lgd.get_texts()[1].set_color('purple')\n",
    "#         lgd.get_texts()[2].set_color('black') \n",
    "\n",
    "        plt.savefig(self.fig_name + 'rewarddiff_integ.' + self.img_format, format=self.img_format, bbox_inches='tight', rasterized=self.rasterized, dpi=self.dpi)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure #2\n",
    "\n",
    "The following 4 cells generate the various performance landscapes shown in Figure 2.\n",
    "\n",
    "The plots will be saved in the Figures folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian-based reward contour with low number of local optima and 1 global optimum\n",
    "\n",
    "ModelObj = Model(123, n_distractors=5, run=0, contour_type='Artificial', img_format='png')\n",
    "Perf = ModelObj.simulate()\n",
    "ModelObj.plot_landscape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian-based reward contour with medium number of local optima and 1 global optimum\n",
    "\n",
    "ModelObj = Model(234, n_distractors=40, run=0, contour_type='Artificial', img_format='png')\n",
    "Perf = ModelObj.simulate()\n",
    "ModelObj.plot_landscape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian-based reward contour with high number of local optima and 1 global optimum\n",
    "\n",
    "ModelObj = Model(3456, n_distractors=160, run=0, contour_type='Artificial', img_format='png')\n",
    "Perf = ModelObj.simulate()\n",
    "ModelObj.plot_landscape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syrinx-based reward contour with 3 global optimum\n",
    "\n",
    "ModelObj = Model(12, run=0, contour_type='Syrinx', reward_contour_path='../../Contours/rc4/Z-T03_P005_n10.npy', img_format='png')\n",
    "Perf = ModelObj.simulate()\n",
    "ModelObj.plot_landscape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure #3\n",
    "\n",
    "The following cell generates the plots shown in Figure 2.\n",
    "\n",
    "The plots will be saved in the Figures folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n"
     ]
    }
   ],
   "source": [
    "# Generate plots within Figure 3\n",
    "\n",
    "ModelObj = Model(177452830, n_distractors=40, run=154, contour_type='Artificial', fig_path='../Figures/', img_format='png', plt_close='False')\n",
    "Perf = ModelObj.simulate()\n",
    "ModelObj.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single pathway architecture\n",
    "\n",
    "Author: Remya Sankar\n",
    "\n",
    "This notebook simulates sensorimotor learning using a single pathway architecture, as explained in the article\n",
    "\"Dual pathway architecture underlying sensorimotor learning in birds\".\n",
    "\n",
    "It serves as a benchmark for the dual pathway architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np                                         # 1.16.2 \n",
    "import matplotlib.pyplot as plt                            # 3.0.3\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.ndimage import filters\n",
    "from scipy.interpolate import interp2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext watermark\n",
    "# %watermark --author \"Remya Sankar\" --date --time --python --machine --iversion --watermark --packages jupyterlab,notebook,matplotlib,viziphant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, rseed=3456, run=0, n_distractors=20, noiseLim=0.2, fig_path='Figures/', eta=0.1, n_days=60, ntrialspday=1000, simulation=True, contour_type='Syrinx', reward_contour_path='../../Contours/rc4/Z-T03_P005_n10.npy', syrinx_param_range = [0, 0.2, 0, 1], benchmark_type='StdRL'):\n",
    "        self.rseed = rseed\n",
    "        self.run = run\n",
    "        self.n_distractors = n_distractors\n",
    "        self.noiseLim = noiseLim\n",
    "        self.fig_path = fig_path\n",
    "        self.eta = eta\n",
    "        self.n_days = n_days                                     # No. of days for learning\n",
    "        self.ntrialspday = ntrialspday                               # No. of trials per day\n",
    "        self.img_format = 'png'\n",
    "        self.fig_name = self.fig_path + str(self.run) + '_' + str(self.rseed) + '_' + str(self.n_distractors) + '_'\n",
    "        self.contour_type = contour_type                         # \"Syrinx\" / \"Artificial\"\n",
    "        self.reward_contour_path = reward_contour_path\n",
    "        self.syrinx_param_range = syrinx_param_range\n",
    "        if simulation == False: self.load_simulation()\n",
    "        self.benchmark_type = benchmark_type # StdRL, DevRL, Annealing\n",
    "        if self.benchmark_type == 'Annealing': self.noiseLim = self.noiseLim/10\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def hill(self, sigma=0.1, center=None):\n",
    "        \"\"\" Randomly assigns the mean and std deviation for the hills in the reward contour. \"\"\"\n",
    "\n",
    "        if center is None:\n",
    "            r = np.sqrt(np.random.uniform(0.0, 1.0))\n",
    "            a = np.random.uniform(0, 2*np.pi)\n",
    "            center = r*np.cos(a), r*np.sin(a)\n",
    "\n",
    "        return center, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def gaussian(self, n=128, center=(0,0), sigma=0.1):\n",
    "        \"\"\" Creates a 2D gaussian distribution, given the center coordinates and std deviation. \"\"\"\n",
    "\n",
    "        X, Y = np.meshgrid(np.linspace(-1, +1, n), np.linspace(-1, +1, n))\n",
    "        x0, y0 = center\n",
    "        D = np.sqrt((X-x0)**2/(2*sigma**2) + (Y-y0)**2/(2*sigma**2))\n",
    "\n",
    "        return 1/(2*np.pi*sigma**2)*np.exp(-D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def generate_gradient(self, n=256):\n",
    "        \"\"\" Redirects to the function that generates the desired contour type \"\"\"\n",
    "        \n",
    "        if self.contour_type == 'Syrinx': return self.generate_gradient_syrinx(n)\n",
    "        elif self.contour_type == 'Artificial': return self.generate_gradient_artificial(n)\n",
    "        else: print(\"Contour type not specified (Syrinx/Artificial).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def generate_gradient_syrinx(self, n=256):\n",
    "        \"\"\" Loads the reward contour from the syrinx model. Outer product and applies a filter.\"\"\"\n",
    "        # Load generated reward contour\n",
    "        Z = np.load(self.reward_contour_path)\n",
    "        Z = Z / Z.max()\n",
    "        \n",
    "        # Transform exponentially\n",
    "        Z = np.power(1000, Z)\n",
    "        Z = Z / Z.max()\n",
    "\n",
    "        # Interpolate\n",
    "        x = np.linspace(0, 1., Z.shape[0])\n",
    "        y = np.linspace(0, .2, Z.shape[1])\n",
    "        \n",
    "        x2 = np.linspace(0, 1., n)\n",
    "        y2 = np.linspace(0, .2, n)\n",
    "        f = interp2d(x, y, Z, kind='cubic')\n",
    "        Z = f(x2, y2)\n",
    "        \n",
    "        Z = (Z-np.min(Z))/(np.max(Z)-np.min(Z))\n",
    "        Z = Z / Z.max()\n",
    "    \n",
    "        targetZpos = np.argwhere(Z==1)[0]\n",
    "        self.targetpos = np.zeros((2))\n",
    "        self.targetpos[0] = (targetZpos[1] / Z.shape[1]) * 2 - 1\n",
    "        self.targetpos[1] = (targetZpos[0] / Z.shape[0]) * 2 - 1\n",
    "                \n",
    "        return  Z / Z.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def generate_gradient_artificial(self, n=256):\n",
    "        \"\"\" Creates the overall reward contour by combining several gaussians. \"\"\"\n",
    "        \n",
    "        # No. of local optima\n",
    "        n_hills = self.n_distractors\n",
    "\n",
    "        # Target i.e. global optima\n",
    "        target_r = np.random.uniform(0,1)\n",
    "        target_theta = np.random.uniform(0,2*np.pi)\n",
    "        self.targetpos = target_r*np.cos(target_theta), target_r*np.sin(target_theta)\n",
    "        hills = [self.hill(0.3, self.targetpos)] # chosen sigma=0.3\n",
    "\n",
    "        # n_hills distractors (0.4 < Ïƒ < 0.7) i.e. local optima\n",
    "        for i in range(n_hills):\n",
    "            hills.append(self.hill(np.random.uniform(0.4, 0.7)))\n",
    "\n",
    "        # Build gradient landscape\n",
    "        Z = np.zeros((n,n))\n",
    "        for (center, sigma) in hills:\n",
    "            Z = np.maximum(Z, self.gaussian(n, center, sigma))\n",
    "            # Z = Z + gaussian(n, center, sigma)    # For a smoother reward profile    \n",
    "        \n",
    "        return  Z / Z.max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def read_gradient(self, Z, p):\n",
    "        \"\"\" Returns height of reward profile at given position. \"\"\"\n",
    "\n",
    "        x = min(max(p[0], -1), 1)\n",
    "        y = min(max(p[1], -1), 1)\n",
    "        col = int(((x + 1)/2) * (Z.shape[1]-1))\n",
    "        row = int(((y + 1)/2) * (Z.shape[0]-1))\n",
    "\n",
    "        return Z[row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def running_mean(self, x, N=5):\n",
    "        \"\"\" Returns the running average of an array. \"\"\"\n",
    "\n",
    "        rm = np.convolve(x, np.ones(N)/N, mode='valid')\n",
    "        padded_rm = np.ones(np.shape(x)) * rm[-1]\n",
    "        padded_rm[:rm.size] = rm\n",
    "\n",
    "        return padded_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def var_windows(self, x, n=50):\n",
    "        \"\"\" Returns the windowed variance of an array. \"\"\"\n",
    "\n",
    "        if x.shape[1] == 2: distances = np.sqrt(np.sum(x**2, axis=-1))\n",
    "        else: distances = x\n",
    "        a = np.reshape(distances, (int(self.ntrials/n), n))\n",
    "        win_var = np.var(a, axis=1)\n",
    "\n",
    "        return win_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def length(self, Z):\n",
    "        \"\"\" Returns the length of a vector. \"\"\"\n",
    "\n",
    "        return np.sqrt((Z*Z).sum())\n",
    "\n",
    "class Model(Model):\n",
    "    def clip(self, Z, lim=1):\n",
    "        \"\"\" Bounds the vector to the range of a circle of radius=lim. \"\"\"\n",
    "        return np.clip(Z, -lim, lim)\n",
    "#         if self.length(Z) > lim: return Z / self.length(Z) * lim\n",
    "#         else:             return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def find_peaks(self, Z, n=256):\n",
    "        \"\"\" Finds the peaks in a given contour. \"\"\"\n",
    "\n",
    "#         peaks = []\n",
    "        n_peaks = 0\n",
    "        for x in np.arange(n):\n",
    "            for y in np.arange(n):\n",
    "                curr = Z[x,y]\n",
    "                left_x = np.maximum(0,x-1)\n",
    "                right_x = np.minimum(n-1,x+1)\n",
    "                bottom_y = np.maximum(0,y-1)\n",
    "                top_y = np.minimum(n-1,y+1)\n",
    "\n",
    "                if curr > Z[left_x,y] and curr > Z[x,bottom_y] and curr > Z[x,top_y] and curr > Z[right_x,y]:\n",
    "#                     peaks.append([x/(n-1) * 2 - 1, y/(n-1) * 2 - 1])\n",
    "                    n_peaks +=1\n",
    "\n",
    "        return n_peaks #np.array(peaks).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def simulate(self):\n",
    "        \"\"\" Runs the simulation and returns the performance metrics. \"\"\"\n",
    "\n",
    "        # Overall simulation parameters\n",
    "        np.random.seed(self.rseed)\n",
    "\n",
    "        # --- Simulated annealing --- #\n",
    "\n",
    "        self.Z = self.generate_gradient()  # Creates reward profile\n",
    "\n",
    "        # Parameters\n",
    "        stepsize = self.noiseLim                             # Radius of local exploration\n",
    "        eta = self.eta                                            # Learning rate of BG pathway\n",
    "        HL_eta = self.eta/100                                      # Learning rate of cortical pathway\n",
    "        self.ntrials = self.n_days * self.ntrialspday        # Total no. of trials\n",
    "\n",
    "        # For tracking purposes\n",
    "        self.Noise = np.zeros((self.ntrials,2))              # Tracks noise across trials\n",
    "        self.R = np.zeros((self.ntrials,1))                    # Tracks reward obtained across trials\n",
    "        self.R_BG = np.zeros((self.ntrials,1))                    # Tracks reward obtained across trials\n",
    "        self.P = np.zeros((self.ntrials,2))                  # Tracks overall trajectory\n",
    "        self.P_rl = np.zeros((self.ntrials,2))               # Tracks mean of BG exploration \n",
    "        self.P_hl = np.zeros((self.ntrials,2))               # Tracks location of cortical pathway\n",
    "        self.W_hl = np.zeros((self.ntrials,))                 # Tracks influence of cortical pathway across trials\n",
    "        self.W_rl = np.ones((self.ntrials,))                  # Tracks influence of BG pathway across trials\n",
    "        self.BG = np.zeros((self.ntrials,2))                 # Tracks weighted output of BG pathway\n",
    "        self.CTX = np.zeros((self.ntrials,2))                # Tracks weighted output of cortical pathway\n",
    "        self.Acceptance = np.zeros((self.ntrials))                # Tracks weighted output of cortical pathway\n",
    "\n",
    "\n",
    "        # Changing influence of cortical and BG pathway\n",
    "        q = np.linspace(0, 10, self.ntrials+1)[1:]            \n",
    "        if self.benchmark_type == 'DevRL':\n",
    "            self.W_hl = np.exp(-.5/q)\n",
    "            self.W_rl = 1-np.exp(-1/q)\n",
    "\n",
    "        self.Temperature = 1-np.exp(-1/q) \n",
    "        \n",
    "\n",
    "        # Initialisations for first trial\n",
    "        p_hl = np.zeros((2,))\n",
    "        p_rl = np.random.uniform(-1, 1, p_hl.shape)\n",
    "        w_hl = 0\n",
    "        w_rl = 1\n",
    "        BG_cntr = w_rl * p_rl\n",
    "        ctx_cntr = w_hl * p_hl\n",
    "        p = ctx_cntr + BG_cntr\n",
    "\n",
    "        R_p = self.read_gradient(self.Z, p)\n",
    "        R_p_rl = R_p\n",
    "\n",
    "        # Track\n",
    "        self.R[0] = R_p\n",
    "        self.R_BG[0] = R_p_rl\n",
    "        self.P[0] = p\n",
    "        self.P_rl[0] = p_rl \n",
    "        self.P_hl[0] = p_hl\n",
    "        self.W_rl[0] = 1\n",
    "        self.BG[0] = BG_cntr\n",
    "        self.CTX[0] = ctx_cntr\n",
    "\n",
    "        # Simulate each day\n",
    "        for day,k in enumerate(np.linspace(0, 10, self.n_days)):\n",
    "\n",
    "            # Simulate each trial in a day\n",
    "            for i,t in enumerate(np.linspace(0, 10, self.ntrialspday)):        \n",
    "\n",
    "                j = day * self.ntrialspday + i \n",
    "                if j==0:\n",
    "                    i+=1                                         # j=0 is already calculated during initialisations\n",
    "                    j+=1\n",
    "\n",
    "                w_rl = self.W_rl[j]\n",
    "                w_hl = self.W_hl[j]\n",
    "                temperature = self.Temperature[j]\n",
    "\n",
    "                # Local exploration\n",
    "                noise = np.random.uniform(-1,1, p_hl.shape) * stepsize\n",
    "                BG_cntr = self.clip(p_rl + w_rl * noise)\n",
    "                p = BG_cntr\n",
    "\n",
    "                # Performance evaluation\n",
    "                R_p = self.read_gradient(self.Z, p)\n",
    "                prev_r = np.mean( self.R[ np.maximum(0,j-100) : j ] )\n",
    "                diff = R_p - prev_r\n",
    "                \n",
    "                # Annealing specific\n",
    "                diff_annealing = R_p - R_p_rl #(negative diff signals new position is better)\n",
    "                acceptance = np.exp(diff_annealing / temperature)\n",
    "\n",
    "                # RL update\n",
    "                if self.benchmark_type == 'Annealing': # if new is better, move definitely, else, probabilistically\n",
    "                    if diff > 0 or np.random.uniform(0,1) < acceptance: p_rl, R_p_rl = p, R_p\n",
    "                else:\n",
    "                    if diff > 0:    p_rl = self.clip(p_rl + eta * w_rl * noise)\n",
    "\n",
    "                # Record trajectory\n",
    "                self.P[j] = p\n",
    "                self.P_rl[j] = p_rl\n",
    "                self.Noise[j] = noise\n",
    "                self.BG[j] = BG_cntr\n",
    "                self.R[j] = R_p\n",
    "                self.R_BG[j] = R_p_rl\n",
    "                self.Acceptance[j] = acceptance * (diff_annealing<=0)\n",
    "\n",
    "#         self.plot_results()\n",
    "        \n",
    "        self.distance_optima = self.distance_performance()\n",
    "        self.reward_performance = np.mean(self.R[-5 * self.ntrialspday:]) \n",
    "        self.n_local_optima = self.find_peaks(self.Z)\n",
    "        self.performance_metric = [self.reward_performance, self.distance_optima, self.n_local_optima]           \n",
    "        \n",
    "#         np.save(self.fig_name + 'object_variables', vars(self)) # Use better method\n",
    "\n",
    "        return self.performance_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plotting ---- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def load_simulation(self):\n",
    "        \"\"\" Loads previously saved simulation. \"\"\"\n",
    "        \n",
    "        stored_state=(np.load(self.fig_name + 'object_variables.npy')).item()\n",
    "        self.__dict__ = stored_state     \n",
    "        \n",
    "        np.save(self.fig_name + 'object_variables', vars(self)) # Use better method\n",
    "        \n",
    "        return self.performance_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def distance_performance(self):\n",
    "        \"\"\" Computes the performance metric based on distance from global optima. \"\"\"\n",
    "        \n",
    "        if self.contour_type == 'Syrinx':\n",
    "        \n",
    "            optima1 = np.array([85,85]) / self.Z.shape * 2 - 1\n",
    "            optima2 = np.array([194,56]) / self.Z.shape * 2 - 1\n",
    "            optima3 = np.array([0,113]) / self.Z.shape * 2 - 1\n",
    "\n",
    "            position_last5days = self.P[-5 * self.ntrialspday:]\n",
    "\n",
    "            distance_optima1 = np.mean(np.sqrt(np.sum((position_last5days - optima1)**2, axis=1)))\n",
    "            distance_optima2 = np.mean(np.sqrt(np.sum((position_last5days - optima2)**2, axis=1)))\n",
    "            distance_optima3 = np.mean(np.sqrt(np.sum((position_last5days - optima3)**2, axis=1)))\n",
    "\n",
    "            return [distance_optima1, distance_optima2, distance_optima3]\n",
    "        \n",
    "        elif self.contour_type == 'Artificial':\n",
    "            \n",
    "            optima1 = self.targetpos\n",
    "            position_last5days = self.P[-5 * self.ntrialspday:]\n",
    "            distance_optima1 = np.mean(np.sqrt(np.sum((position_last5days - optima1)**2, axis=1)))\n",
    "            \n",
    "            return [distance_optima1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_results(self):\n",
    "        \"\"\" Specifies the different plots to be generated. \"\"\"\n",
    "        self.plot_trajectory()\n",
    "        self.plot_exploration()\n",
    "        self.plot_coordinates()\n",
    "        self.plot_reward()\n",
    "#         self.plot_RLdiff()\n",
    "#         self.plot_variance()\n",
    "#         self.plot_CI()        \n",
    "#         self.plot_reward_variance()\n",
    "        \n",
    "#         np.save(self.fig_name + 'object_variables', vars(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_gradient(self, ax, Z):\n",
    "        \"\"\" Plots reward contour. \"\"\"\n",
    "\n",
    "        contour = ax.contourf(Z, 30, extent=[-1,1,-1,1], cmap=\"gray_r\", alpha=.25)\n",
    "\n",
    "        contour = ax.contour(Z, 10, extent=[-1,1,-1,1],\n",
    "                             colors=\"black\",  alpha=.5, linewidths=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_trajectory(self):\n",
    "        \"\"\" Plots the trajectory of the model output and cortical pathway over the simulation. \"\"\"\n",
    "\n",
    "        figure = plt.figure(figsize=(8,8))\n",
    "        ax = plt.subplot(frameon=False)\n",
    "\n",
    "        # Plot reward contour as circles around hills    \n",
    "        self.plot_gradient(ax, self.Z)\n",
    "\n",
    "        # Plot reward contour as a color plot\n",
    "        im = ax.imshow(self.Z , vmin=np.min(self.Z), vmax=np.max(self.Z), cmap='Purples', extent=[-1,1,-1,1], origin='lower')\n",
    "#         ax.invert_yaxis()                                                          # Labels read top-to-bottom\n",
    "\n",
    "        # Plot trajectory\n",
    "        if self.benchmark_type=='Annealing':\n",
    "            ax.plot(self.P[:,0],self.P[:,1], color=\"black\", lw=0, marker=',', alpha=0.5, label='Candidate')\n",
    "            ax.plot(self.P_rl[:,0],self.P_rl[:,1], color=\"green\", lw=0, marker=',', alpha=0.5, label='Current')\n",
    "        else:\n",
    "            ax.plot(self.P[:,0],self.P[:,1], color=\"black\", lw=0, marker=',', alpha=0.5, label='Candidate')\n",
    "            ax.plot(self.P_rl[:,0],self.P_rl[:,1], color=\"green\", lw=0, marker=',', alpha=0.5, label='Current')\n",
    "            \n",
    "        # Annotations\n",
    "#         ax.scatter(self.CTX[0,0],self.CTX[0,1], color=\"sienna\", marker=\"o\",\n",
    "#                    linewidths=3, facecolors=\"sienna\", zorder=10, label='Initial point')\n",
    "        ax.scatter(self.P[-1,0],self.P[-1,1], s=100, color=\"orange\", marker=\"x\",\n",
    "                   linewidths=3, facecolors=\"orange\", zorder=10, label='Final point')\n",
    "\n",
    "#         ax.annotate('End point', (self.P[-1,0],self.P[-1,1]),\n",
    "#                     xytext=(0.1, -0.55), xycoords='data',\n",
    "#                     arrowprops=dict(width=1, facecolor='black', shrink=0.2),\n",
    "#                     fontsize=20,\n",
    "#                     horizontalalignment='right', verticalalignment='top')\n",
    "        \n",
    "#         ax.annotate('Global optima', (self.targetpos[0],self.targetpos[1]),\n",
    "#                     xytext=(0.7, 0.9), xycoords='data',\n",
    "#                     arrowprops=dict(width=1, facecolor='black'),\n",
    "#                     fontsize=20,\n",
    "#                     horizontalalignment='right', verticalalignment='top')\n",
    "        \n",
    "        # Display colorbar\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.5)\n",
    "        cbar = figure.colorbar(im, cax=cax)\n",
    "        cbar.set_label('Performance metric (R)', rotation=270, fontsize=20, labelpad=25)\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        ax.set_xticks(np.linspace(-1, 1, 5))\n",
    "        ax.set_xticklabels(np.linspace(self.syrinx_param_range[2], self.syrinx_param_range[3], 5))\n",
    "        ax.set_yticks(np.linspace(-1, 1, 5))\n",
    "        ax.set_yticklabels(np.linspace(self.syrinx_param_range[0], self.syrinx_param_range[1], 5))\n",
    "        \n",
    "        ax.set_xlabel('Tension')\n",
    "        ax.set_ylabel('Pressure')\n",
    "\n",
    "\n",
    "        # ax.legend(loc='upper left', bbox_to_anchor=[-0.1,1])\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(self.fig_name + 'trajectory.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_exploration(self):\n",
    "        \"\"\" Plots the contribution of the exploratory pathway over the simulation. \"\"\"\n",
    "\n",
    "        figure = plt.figure(figsize=(8,8))\n",
    "        ax = plt.subplot(aspect=1, frameon=False)\n",
    "\n",
    "        # Plot exploration across time\n",
    "        exp_cm = plt.set_cmap('plasma')\n",
    "        exp_x = self.BG[:,0]\n",
    "        exp_y = self.BG[:,1]\n",
    "        exp_z = np.arange(exp_x.size)\n",
    "        exp_sc = plt.scatter(exp_x, exp_y, c=exp_z, s=1, cmap=exp_cm, marker='.', vmin=0, vmax=exp_x.size, alpha=0.5)\n",
    "\n",
    "        # Annotations\n",
    "        ax.scatter(0, 0, color=\"black\", marker=\"o\",\n",
    "                   linewidths=3, facecolors=\"black\", zorder=10, label='$P_{ctx}$')\n",
    "\n",
    "#         ax.annotate('$P_{ctx}$', (0, 0),\n",
    "#                     xytext=(-0.3, 0.3), xycoords='data',\n",
    "#                     arrowprops=dict(width=1, facecolor='black', shrink=0.1),\n",
    "#                     fontsize=30,\n",
    "#                     horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "        # Display colorbar\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.5)\n",
    "        cbar = figure.colorbar(exp_sc, cax=cax)\n",
    "        cbar.set_ticks(np.linspace(0, exp_x.size, self.n_days/10+1))\n",
    "        cbar.set_ticklabels(np.arange(0, self.n_days+1, 10))\n",
    "        cbar.set_label('Day', rotation=270, fontsize=20, labelpad=20)\n",
    "\n",
    "        ax.set_xlim(-1,1)\n",
    "        ax.set_ylim(-1,1)\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "\n",
    "        ax.get_xaxis().set_ticks([])\n",
    "        ax.get_yaxis().set_ticks([])\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(self.fig_name + 'exploration.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_coordinates(self):\n",
    "        \"\"\" Plots the model output over time. \"\"\"\n",
    "\n",
    "        figure, (ax1, ax2) = plt.subplots(2,1)\n",
    "\n",
    "        # Display x axis in days\n",
    "        x = np.arange(self.ntrials)\n",
    "        x = x/self.ntrialspday\n",
    "\n",
    "        # Plot running average of cortical output (brown), BG output (grey) and total output (black)\n",
    "        ax1.plot(x, self.running_mean(self.P[:,0]), color=\"black\", lw=0.5, label='Total output')\n",
    "        ax1.plot(x, self.running_mean(self.CTX[:,0]), color=\"sienna\", lw=2, label='Cortical output')\n",
    "        ax1.plot(x, self.running_mean(self.BG[:,0]), color=\"grey\", lw=0.5, label='BG output', alpha=0.5)\n",
    "        ax1.axhline(y=0, linestyle='--', color='black', alpha=0.1)\n",
    "        ax1.axhline(y=self.targetpos[0], linestyle='--', color='black', label='Global optimum')\n",
    "\n",
    "        ax2.plot(x, self.running_mean(self.P[:,1]), color=\"black\", lw=0.5, label='Total output')\n",
    "        ax2.plot(x, self.running_mean(self.CTX[:,1]), color=\"sienna\", lw=2, label='Cortical output')\n",
    "        ax2.plot(x, self.running_mean(self.BG[:,1]), color=\"grey\", lw=0.5, label='BG output', alpha=0.5)\n",
    "        ax2.axhline(y=0, linestyle='--', color='black', alpha=0.1)\n",
    "        ax2.axhline(y=self.targetpos[1], linestyle='--', color='black', label='Global optimum')\n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.spines['bottom'].set_visible(False)\n",
    "\n",
    "        ax1.get_xaxis().set_ticks([])\n",
    "\n",
    "        ax1.set_ylabel('Coordinate X')\n",
    "        ax1.set_ylim(-1.1, 1.1)\n",
    "\n",
    "        ax2.set_ylabel('Coordinate Y')\n",
    "        ax2.set_xlabel('Days')\n",
    "        ax2.set_ylim(-1.1, 1.1)\n",
    "\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(self.fig_name + 'coordinates.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_reward(self):\n",
    "        \"\"\" Plots the reward obtained over time. \"\"\"\n",
    "\n",
    "        figure, ax = plt.subplots(1)\n",
    "        \n",
    "        # Display x axis in days\n",
    "        x = np.linspace(0, self.n_days, self.ntrials)\n",
    "\n",
    "        if self.benchmark_type=='Annealing':\n",
    "            ax.plot(x, self.Acceptance, color=\"orange\", lw=0, label='Acceptance', alpha=0.3, marker=',')\n",
    "            ax.plot(x, self.R_BG, color=\"purple\", lw=0, alpha=0.7, label='Reward', marker=',')\n",
    "        else:\n",
    "            ax.plot(x, self.R, color=\"purple\", lw=0, alpha=0.7, label='Reward', marker=',')\n",
    "            ax.plot(x, self.W_rl * self.Noise[:,0], color=\"grey\", lw=0.5, alpha=0.4, label='Noise weighted')\n",
    "            ax.plot(x, self.Noise[:,0], color=\"grey\", lw=0.5, alpha=0.2, label='Noise')\n",
    "\n",
    "\n",
    "        ax.set_ylim(-0.45, 1.1)\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('Days')\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        plt.savefig(self.fig_name + 'reward.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_influence(self):\n",
    "        \"\"\" Plots the change in influence of the two pathways over time. \"\"\"\n",
    "\n",
    "        figure, ax = plt.subplots(1)\n",
    "\n",
    "        ax.plot(self.W_hl, color=\"sienna\", lw=1, label='Cortical influence')\n",
    "        ax.plot(self.W_rl, color=\"grey\", lw=1, label='BG influence')\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        ax.set_xlabel('Trials')\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_RLdiff(self):\n",
    "        \"\"\" Plots the change in the cortical output per trial and per day. \"\"\"\n",
    "\n",
    "        figure, ax1 = plt.subplots(1)\n",
    "\n",
    "        rldiff = np.sqrt(np.sum((self.BG[1:] - self.BG[:-1])**2, axis=-1))\n",
    "        \n",
    "        # Display x axis in days\n",
    "        x = np.linspace(0, self.n_days, self.ntrials)\n",
    "\n",
    "        ax1.plot(x[:-1], rldiff, color=\"black\", marker=',', lw=0, alpha=0.2)\n",
    "        ax1.set_ylabel('Trial by trial difference')\n",
    "        ax1.set_xlabel('Days')\n",
    "        \n",
    "        ax2 = ax1.twinx() \n",
    "        \n",
    "        P2 = self.BG.reshape((self.n_days, self.ntrialspday, 2))\n",
    "        BG_start = P2[:,0]\n",
    "        BG_end = P2[:,-1]\n",
    "        rldiff_day = np.sqrt(np.sum((BG_end - BG_start)**2, axis=-1))\n",
    "\n",
    "        x = np.arange(0, self.n_days)\n",
    "        ax2.plot(x, rldiff_day, color=\"sienna\", marker='.', lw=0)\n",
    "        \n",
    "        ax2.set_ylabel('Day wise difference', color=\"sienna\")\n",
    "        ax2.tick_params(axis ='y', labelcolor = \"sienna\", color=\"sienna\") \n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "\n",
    "        plt.savefig(self.fig_name + 'RL_diff.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_variance(self):\n",
    "        \"\"\" Plots the variance over time. \"\"\"\n",
    "\n",
    "        figure, ax1 = plt.subplots(1)\n",
    "        \n",
    "        window_size = 50\n",
    "        \n",
    "        # Display x axis in days\n",
    "        x = np.linspace(0, self.n_days, self.ntrials/window_size)\n",
    "\n",
    "        ax1.plot(x, self.var_windows(self.P, window_size), color=\"black\", marker='.', lw=0, alpha=0.5, label='Total')\n",
    "        ax1.plot(x, self.var_windows(self.BG, window_size), color=\"grey\", marker='x', lw=0, alpha=0.5, label='BG')\n",
    "        ax1.set_ylabel('Variance')\n",
    "        ax1.set_xlabel('Days')\n",
    "    \n",
    "        ax2 = ax1.twinx() \n",
    "        ax2.plot(x, self.var_windows(self.CTX, window_size), color=\"sienna\", marker='.', lw=0, alpha=0.5, label='CTX')\n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.tick_params(axis ='y', labelcolor = \"sienna\", color=\"sienna\")\n",
    "        \n",
    "        ax1.legend()\n",
    "        ax2.set_ylabel('Cortex variance', color=\"sienna\")\n",
    "\n",
    "        plt.savefig(self.fig_name + 'variance.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_CI(self):\n",
    "        \"\"\" Plots the consolidation index over time. \"\"\"\n",
    "\n",
    "        variance = self.var_windows(self.P)\n",
    "        variance = variance.reshape((self.n_days, int(variance.size/self.n_days)))\n",
    "        variance_start = variance[:,0]\n",
    "        variance_end = variance[:,-1]\n",
    "        span = variance_end - variance_start\n",
    "        shift = variance_start[1:] - variance_end[:-1]\n",
    "        CI = shift/span[:-1]\n",
    "        CI = CI[(CI < 5) & (CI > -5)]\n",
    "        \n",
    "        figure, ax1 = plt.subplots(1)\n",
    "        \n",
    "        n, bins, patches = plt.hist(CI, 40, density=True, facecolor='black', alpha=0.75)\n",
    "        \n",
    "        ax1.set_xlabel('Consolidation index (shift/span)')\n",
    "        ax1.set_ylabel('Density')\n",
    "    \n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        \n",
    "        plt.savefig(self.fig_name + 'CI.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Model):\n",
    "    def plot_reward_variance(self):\n",
    "        \"\"\" Plots the variance in reward obtained over time. \"\"\"\n",
    "\n",
    "        figure, ax1 = plt.subplots(1)\n",
    "\n",
    "        window_size = 50\n",
    "\n",
    "        # Display x axis in days\n",
    "        x = np.linspace(0, self.n_days, self.ntrials/window_size)\n",
    "        \n",
    "        ax1.plot(x, self.var_windows(self.R, window_size), color=\"purple\", marker='.', lw=0, alpha=0.5, label='Total')\n",
    "        ax1.set_ylabel('Variance')\n",
    "        ax1.set_xlabel('Days')\n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        \n",
    "        ax1.legend()\n",
    "\n",
    "        plt.savefig(self.fig_name + 'reward_variance.' + self.img_format, format=self.img_format)\n",
    "        plt.close(figure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample simulations of benchmark with different algorithms (StdRL, DevRL, Annealing) on different performance landscapes (\"Syrinx\", \"Artificial\").\n",
    "\n",
    "Simulate varying benchmark scenarios by changing\n",
    "- the seed for the random number generator\n",
    "- performance landscape (contour_type='Artificial'/'Syrinx')\n",
    "- learning rule (benchmark_type='Annealing'/'StdRL'/'DevRL')\n",
    "- other simulation parameters, such as noise level, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n"
     ]
    }
   ],
   "source": [
    "# ModelObj = Model(3456, contour_type='Artificial', benchmark_type='Annealing')\n",
    "# Perf = ModelObj.simulate()\n",
    "# ModelObj.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
